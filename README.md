# 1. Introduction
In recent years, social media platforms have become an important place that provides an environment to its users, for expressing their thoughts and ideas, sharing content, and doing social interaction.
Unfortunately, toxicity has become a serious issue affecting a wide range of users causing different psychological problems like depression and even suicidality.
Toxicity in online conversation can be defined as anything rude, disrespectful, troll, or anything else that is likely to initiate a discussion, offend someone, spread hatred and/or false information, etc. Toxicity online poses a serious challenge for platforms and publishers. Online abuse and harassment suppress important voices in conversation, forcing already marginalized people offline.
The prevalence of online toxicity has been growing rapidly in recent years, and the problem is a major concern. In some cases, toxic comments online have even caused real-life violence.
Social media platforms depend on thousands of human reviewers who struggle to moderate the ever-increasing volume of toxicity. In 2019, it was reported that Facebook moderators are at risk of suffering from PTSD (post-traumatic stress disorder) as a result of repeated exposure to such distressing content.


Hence, solving this problem by machine learning can help manage the rising volume of toxicity while limiting human exposure to it, and help mitigate toxicity and ensure healthy conversations online.
